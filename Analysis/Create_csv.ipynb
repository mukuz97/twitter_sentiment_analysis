{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from pymongo import MongoClient\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongoClient = MongoClient()\n",
    "db = mongoClient.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ConfigParser()\n",
    "parser.read('../config.ini')\n",
    "query_terms = list(parser.get('FILTER', 'filter_terms').split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling method\n",
    "\n",
    "- Taking 1% tweets of each company\n",
    "- Create a csv file of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text(status):\n",
    "    if \"retweeted_status\" in status: # Check if Retweet\n",
    "        try:\n",
    "            return status[\"retweeted_status\"][\"extended_tweet\"][\"full_text\"]\n",
    "        except KeyError:\n",
    "            return status[\"retweeted_status\"][\"text\"]\n",
    "    else:\n",
    "        try:\n",
    "            return status[\"extended_tweet\"][\"full_text\"]\n",
    "        except KeyError:\n",
    "            return status[\"text\"]\n",
    "\n",
    "def get_tweet_source(status):\n",
    "    if \"retweeted_status\" in status:\n",
    "        return status[\"retweeted_status\"]['id_str']\n",
    "    else:\n",
    "        return status['id_str']\n",
    "\n",
    "def extract_source_device(html_data):\n",
    "    soup = BeautifulSoup(html_data, 'html.parser')\n",
    "    return soup.text\n",
    "\n",
    "def extract_tweet_data(status):\n",
    "    data = []\n",
    "    data.append(get_full_text(status))\n",
    "    data.append(int(status['timestamp_ms'])/1000)\n",
    "    data.append(status['user']['screen_name'])\n",
    "    data.append(get_tweet_source(status))\n",
    "    data.append(status['id_str'])\n",
    "    data.append(status['user']['location']) # User location is useless\n",
    "    data.append(extract_source_device(status['source']))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google samples: 4480\n",
      "google sample file created\n",
      "tesla samples: 777\n",
      "tesla sample file created\n",
      "apple samples: 4516\n",
      "apple sample file created\n",
      "spacex samples: 94\n",
      "spacex sample file created\n",
      "amazon samples: 3241\n",
      "amazon sample file created\n",
      "microsoft samples: 442\n",
      "microsoft sample file created\n",
      "facebook samples: 3395\n",
      "facebook sample file created\n"
     ]
    }
   ],
   "source": [
    "for term in query_terms:\n",
    "    count = db[term].estimated_document_count()\n",
    "    tweets = db[term].find()\n",
    "    sample_tweets = []\n",
    "    for index in np.random.choice(count, int(count / 100)):\n",
    "        sample_tweets.append(tweets[int(index)])\n",
    "    print(term, 'samples:', len(sample_tweets))\n",
    "\n",
    "    with open('../data/' + term + '_sample.csv', 'w', encoding='utf-8') as file:\n",
    "        csvwriter = csv.writer(file)\n",
    "        for tweet in sample_tweets:\n",
    "            csvwriter.writerow(extract_tweet_data(tweet))\n",
    "        print(term, 'sample file created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Full Data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in query_terms:\n",
    "    with open('../data/' + term + '.csv', 'w', encoding='utf-8') as file:\n",
    "        csvwriter = csv.writer(file)\n",
    "        for tweet in db[term].find():\n",
    "            csvwriter.writerow(extract_tweet_data(tweet))\n",
    "        print(term, 'file created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
